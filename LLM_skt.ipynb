{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c9a12-a482-4767-b262-e35613df802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import random\n",
    "from transformers import set_seed\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import langchain\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever\n",
    "from langchain.document_loaders import PDFPlumberLoader, PyMuPDFLoader, PyPDFLoader, UnstructuredPDFLoader\n",
    "\n",
    "import peft\n",
    "from peft import PeftModel\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9e73e-0e85-4106-8e4f-d4745d2b0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.model_configs = {\n",
    "            'skt/kogpt2-base-v2': {\n",
    "                'quantization_config': BitsAndBytesConfig(\n",
    "                    load_in_8bit=True,\n",
    "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                ),\n",
    "                'torch_dtype': torch.float16,\n",
    "                'max_token': 512,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        self.llm_model = 'skt/kogpt2-base-v2'\n",
    "        self.llm_model_config = self.model_configs[self.llm_model]\n",
    "        self.llm_peft = False\n",
    "        self.llm_peft_checkpoint = None\n",
    "\n",
    "        self.embed_models = ['distilbert-base-uncased', 'google/mobilebert-uncased']\n",
    "        self.embed_model = self.embed_models[1]\n",
    "\n",
    "        self.pdf_loader = 'pymupdf'\n",
    "\n",
    "        self.base_directory = './'\n",
    "        self.train_csv_path = os.path.join(self.base_directory, 'train.csv')\n",
    "        self.test_csv_path = os.path.join(self.base_directory, 'test.csv')\n",
    "        self.chunk_size = 256\n",
    "        self.chunk_overlap = 16\n",
    "\n",
    "        self.ensemble = True\n",
    "        self.bm25_w = 0.5\n",
    "        self.faiss_w = 0.5\n",
    "\n",
    "        self.is_submit = True\n",
    "        self.eval_sum_mode = False\n",
    "\n",
    "        self.output_dir = 'test_results'\n",
    "        self.output_csv_file = f\"{self.llm_model.replace('/', '_')}_{self.embed_model.split('/')[1]}_pdf{self.pdf_loader}_chks{self.chunk_size}_chkovp{self.chunk_overlap}_bm25{self.bm25_w}_faiss{self.faiss_w}_mix_submission.csv\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "\n",
    "args = Opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f1306-883b-4181-b32b-07af2b4e6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_llm_pipeline():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.llm_model)\n",
    "    tokenizer.use_default_system_prompt = False\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.llm_model,\n",
    "        quantization_config=args.llm_model_config['quantization_config'],\n",
    "        torch_dtype=args.llm_model_config['torch_dtype'],\n",
    "        device_map='auto',\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    if args.llm_peft:\n",
    "        model = PeftModel.from_pretrained(model, args.llm_peft_checkpoint)\n",
    "\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task='text-generation',\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=args.llm_model_config['max_token']\n",
    "    )\n",
    "\n",
    "    return HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b09eb1-8da7-4177-b9be-1f717485ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_path(path):\n",
    "    return unicodedata.normalize('NFC', path)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n'.join([doc.page_content for doc in docs])\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    md_text = pymupdf4llm.to_markdown(file_path)\n",
    "    header_split = [\n",
    "        ('#', 'header I'),\n",
    "        ('##', 'header II'),\n",
    "        ('###', 'header III'),\n",
    "    ]\n",
    "\n",
    "    md_header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=header_split, strip_headers=False)\n",
    "    md_chunks = md_header_splitter.split_text(md_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=args.chunk_size, chunk_overlap=args.chunk_overlap\n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(md_chunks)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d383ca-c2e8-408b-bb1d-04026c4fca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db(chunks, model_path, method='faiss'):\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    db = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "def process_single_pdf(pdf_path):\n",
    "\n",
    "    chunks = process_pdf(pdf_path)\n",
    "    \n",
    "    db = create_vector_db(chunks, model_path=args.embed_model)\n",
    "    \n",
    "    kiwi_bm25_retriever = KiwiBM25Retriever.from_documents(chunks)\n",
    "    faiss_retriever = db.as_retriever()\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "        retrievers=[kiwi_bm25_retriever, faiss_retriever],\n",
    "        weights=[args.bm25_w, args.faiss_w],\n",
    "        search_type='mmr'\n",
    "    )\n",
    "\n",
    "    del chunks, db, kiwi_bm25_retriever, faiss_retriever\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return retriever\n",
    "\n",
    "def process_questions_for_pdf(pdf_path, questions_df):\n",
    "\n",
    "    retriever = process_single_pdf(pdf_path)\n",
    "\n",
    "    llm_pipeline = setup_llm_pipeline()\n",
    "\n",
    "    answers = []\n",
    "    for _, row in questions_df.iterrows():\n",
    "        question = row['Question']\n",
    "        print(f\"Generating answer for: {question}\")\n",
    "\n",
    "        result = llm_pipeline(question)\n",
    "        # answers.append({\n",
    "        #     'ID': row['SAMPLE_ID'],\n",
    "        #     'Answer': result[0]['generated_text']\n",
    "        # })\n",
    "\n",
    "        if isinstance(result, list):\n",
    "            answer_text = result[0]['generated_text'] if 'generated_text' in result[0] else result[0]\n",
    "        elif isinstance(result, dict):\n",
    "            answer_text = result.get('generated_text', result)\n",
    "        else:\n",
    "            answer_text = result \n",
    "\n",
    "        answers.append({\n",
    "            'SAMPLE_ID': row['SAMPLE_ID'], \n",
    "            'Answer': answer_text\n",
    "        })\n",
    "    \n",
    "    # 메모리 해제\n",
    "    del retriever, llm_pipeline\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d685efe-1765-4797-9d48-cd2fc0b5785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_questions(df):\n",
    "\n",
    "    all_answers = []\n",
    "    unique_paths = df['Source_path'].unique()\n",
    "\n",
    "    for path in tqdm(unique_paths, desc='Processing PDFs'):\n",
    "        pdf_questions_df = df[df['Source_path'] == path]\n",
    "\n",
    "        answers = process_questions_for_pdf(path, pdf_questions_df)\n",
    "        all_answers.extend(answers)\n",
    "\n",
    "    return all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526b385-f64d-4fa0-9053-87b9ee7f31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba4443-913e-4188-9748-aaaec67836e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be338a9b-5bd2-4c3d-afeb-b436fb2d7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44e020-f67b-436e-997a-f031de8cf42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_df = pd.read_csv(args.test_csv_path)\n",
    "    answers = process_test_questions(test_df)\n",
    "    print(answers)\n",
    "\n",
    "    # 결과 저장\n",
    "    output_path = os.path.join(args.output_dir, args.output_csv_file)\n",
    "    pd.DataFrame(answers).to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf0f18-8057-47b0-97c8-450d88453455",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef5dc9-5885-4f17-a87b-fbcb31456ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./test_results/skt_kogpt2-base-v2_mobilebert-uncased_pdfpymupdf_chks512_chkovp32_bm250.5_faiss0.5_mix_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf97284-d0b3-4162-82ba-23a9df9f718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[1, 'Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81252d46-081a-4b7e-9846-e8f68c58cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./test_results/skt_kogpt2-base-v2_mobilebert-uncased_pdfpymupdf_chks512_chkovp32_bm250.5_faiss0.5_mix_submission.csv\").loc[1, 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ef60f-fbd6-4cb4-ac4d-a72369ac91a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
