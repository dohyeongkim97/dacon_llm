{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f4abe1-a294-4d7e-a0ce-b189f45f4f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\exllama.py:12: UserWarning: AutoAWQ could not load ExLlama kernels extension. Details: DLL load failed while importing exl_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load ExLlama kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\exllamav2.py:13: UserWarning: AutoAWQ could not load ExLlamaV2 kernels extension. Details: DLL load failed while importing exlv2_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load ExLlamaV2 kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\gemm.py:14: UserWarning: AutoAWQ could not load GEMM kernels extension. Details: DLL load failed while importing awq_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load GEMM kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\gemv.py:11: UserWarning: AutoAWQ could not load GEMV kernels extension. Details: DLL load failed while importing awq_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load GEMV kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\gemv_fast.py:10: UserWarning: AutoAWQ could not load GEMVFast kernels extension. Details: DLL load failed while importing awq_v2_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load GEMVFast kernels extension. Details: {ex}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import random\n",
    "# from transformers import set_seed\n",
    "\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "# set_seed(seed)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import langchain\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever\n",
    "from langchain.document_loaders import PDFPlumberLoader, PyMuPDFLoader, PyPDFLoader, UnstructuredPDFLoader\n",
    "\n",
    "import peft\n",
    "from peft import PeftModel\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548a1e15-f9ef-46b5-ae65-e2240a3c1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95717a88-c2ab-4040-b900-8cb53136bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800a59a5-1959-40c9-8404-0f59900e5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.model_configs = {\n",
    "            'meta-llama/Meta-Llama-3.1-8B-Instruct':\n",
    "            {\n",
    "                'quantization_config': None,\n",
    "                'torch_dtype': 'auto',\n",
    "                'max_token': 256,\n",
    "            },\n",
    "            \n",
    "            'rtzr/ko-gemma-2-9b-it':{\n",
    "                'quantization_config': BitsAndBytesConfig(\n",
    "                    load_in_4bit= True,\n",
    "                    bnb_4bit_use_double_quant= True,\n",
    "                    bnb_4bit_quant_type= 'nf4',\n",
    "                    bnb_4bit_compute_dtype= torch.bfloat16\n",
    "                ),\n",
    "                'torch_dtype': 'auto',\n",
    "                'max_token': 512\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.llm_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "        self.llm_model_config = self.model_configs[self.llm_model]\n",
    "        self.llm_peft = False\n",
    "        self.llm_peft_checkpoint = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "        # self.embed_models = ['distilbert-base-uncased', 'intfloat/multilingual-e5-large']\n",
    "        self.embed_models = [\"intfloat/multilingual-e5-base\", \"jhgan/ko-sbert-nli\", \"intfloat/multilingual-e5-large\"]\n",
    "        self.embed_model = self.embed_models[1]\n",
    "\n",
    "        self.pdf_loader = 'pymupdf'\n",
    "\n",
    "        self.base_directory = './'\n",
    "        self.train_csv_path = os.path.join(self.base_directory, 'train.csv')\n",
    "        self.test_csv_path = os.path.join(self.base_directory, 'test.csv')\n",
    "        self.chunk_size = 512\n",
    "        self.chunk_overlap = 32\n",
    "\n",
    "        self.ensemble = True\n",
    "        self.bm25_w = 0.5\n",
    "        self.faiss_w = 0.5\n",
    "\n",
    "        self.is_submit = True\n",
    "        self.eval_sum_mode = False\n",
    "\n",
    "        self.output_dir = 'test_results'\n",
    "        self.output_csv_file = f\"{self.llm_model.split('/')[1]}_{self.embed_model.split('/')[1]}_pdf{self.pdf_loader}_chks{self.chunk_size}_chkovp{self.chunk_overlap}_bm25{self.bm25_w}_faiss{self.faiss_w}_mix_submission.csv\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "\n",
    "args = Opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef43c65-ff80-4a34-84ae-5fac61384c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import dotenv\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8aa4f4-2175-45dc-95f3-aeee5a3ca592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20267dda-10b0-48f3-8168-bdae46613669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7471e847-35de-42a5-986b-cb61afee3fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\dohyeong\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "token = os.getenv('token')\n",
    "\n",
    "login(token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d895e10-a3ee-40e9-b525-75fd6bd4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e2e3f5-83e1-4ed9-87e4-de229af1c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "508a9a1d-1628-4206-8a13-2d03c0dbdfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(train_csv_path):\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    return train_df[['Question', 'Answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f8bc4a6-6763-4d99-ac56-d79461a2a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_question_improver(train_df):\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    train_embeddings = model.encode(train_df['Question'].tolist(), convert_to_tensor=True)\n",
    "    return model, train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6faf49b-3a7c-4d3a-80f3-524cb44995a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_question(model, train_embeddings, train_df, question):\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(question_embedding, train_embeddings)\n",
    "    best_index = torch.argmax(cosine_scores).item()\n",
    "    improved_question = train_df['Question'].iloc[best_index]\n",
    "    return improved_question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b753bac5-5b25-4d57-b975-d243ebe41e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad00f2e-733f-4a8a-8711-58030a5b4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20210f41-6d7d-46c4-9b15-02f8d6d5199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "798c6c00-ac95-455b-8ee2-6a088e90abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import disk_offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42014360-39b9-46ec-807c-a8143306c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function disk_offload in module accelerate.big_modeling:\n",
      "\n",
      "disk_offload(model: torch.nn.modules.module.Module, offload_dir: Union[str, os.PathLike], execution_device: Optional[torch.device] = None, offload_buffers: bool = False, preload_module_classes: Optional[List[str]] = None)\n",
      "    Activates full disk offload for a model. As a result, all parameters of the model will be offloaded as\n",
      "    memory-mapped array in a given folder. During the forward pass, parameters will be accessed from that folder and\n",
      "    put on the execution device passed as they are needed, then offloaded again.\n",
      "    \n",
      "    Args:\n",
      "        model (`torch.nn.Module`): The model to offload.\n",
      "        offload_dir (`str` or `os.PathLike`):\n",
      "            The folder in which to offload the model weights (or where the model weights are already offloaded).\n",
      "        execution_device (`torch.device`, *optional*):\n",
      "            The device on which the forward pass of the model will be executed (should be a GPU). Will default to the\n",
      "            model's first parameter device.\n",
      "        offload_buffers (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to offload the buffers with the model parameters.\n",
      "        preload_module_classes (`List[str]`, *optional*):\n",
      "            A list of classes whose instances should load all their weights (even in the submodules) at the beginning\n",
      "            of the forward. This should only be used for classes that have submodules which are registered but not\n",
      "            called directly during the forward, for instance if a `dense` linear layer is registered, but at forward,\n",
      "            `dense.weight` and `dense.bias` are used in some operations instead of calling `dense` directly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(disk_offload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb9680d2-8e93-4b10-889d-04481fd76400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_llm_pipeline():\n",
    "    start_time = time.time()\n",
    "    print('started: ', start_time)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.llm_model)\n",
    "    tokenizer.use_default_system_prompt = False\n",
    "\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.llm_model,\n",
    "        quantization_config=args.llm_model_config['quantization_config'],\n",
    "        torch_dtype=args.llm_model_config['torch_dtype'],\n",
    "        device_map='auto',\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # model = disk_offload(\n",
    "    #     model,\n",
    "    #     offload_dir='./to/offload_folder/'\n",
    "    # )\n",
    "    \n",
    "    if args.llm_peft:\n",
    "        model = PeftModel.from_pretrained(model, args.llm_peft_checkpoint)\n",
    "\n",
    "        \n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task='text-generation',\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=args.llm_model_config['max_token']\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Model loading time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b0831b5-cc64-4d78-96b8-fe008d572c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started:  1724271929.6872954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ae7f3dd9db4ae59b1cec63dfbb08ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 완전히 로드되지 않았습니다. 디스크 오프로드를 수행할 수 없습니다.\n",
      "Model loading time: 1.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = setup_llm_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3afbc0d9-d8d8-41af-bc3e-ab9b09ced7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_path):\n",
    "    md_text = pymupdf4llm.to_markdown(file_path)\n",
    "    header_split = [\n",
    "        ('#', 'header I'),\n",
    "        ('##', 'header II'),\n",
    "        ('###', 'header III'),\n",
    "    ]\n",
    "\n",
    "    md_header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=header_split, strip_headers=False)\n",
    "    md_chunks = md_header_splitter.split_text(md_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=args.chunk_size, chunk_overlap=args.chunk_overlap\n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(md_chunks)\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c941b136-7b3f-49f2-9525-7cdb18456687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db(chunks, model_path, method='faiss'):\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    db = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d6608a9-87c4-490f-a348-d895ddfd19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_pdf(pdf_path):\n",
    "    chunks = process_pdf(pdf_path)\n",
    "    db = create_vector_db(chunks, model_path=args.embed_model)\n",
    "    \n",
    "    kiwi_bm25_retriever = KiwiBM25Retriever.from_documents(chunks)\n",
    "    faiss_retriever = db.as_retriever()\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "        retrievers=[kiwi_bm25_retriever, faiss_retriever],\n",
    "        weights=[args.bm25_w, args.faiss_w],\n",
    "        search_type='mmr'\n",
    "    )\n",
    "\n",
    "    del chunks, db, kiwi_bm25_retriever, faiss_retriever\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3b2d1d2-91dd-49f8-8ecb-5ba88b296714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_questions_for_pdf(pdf_path, questions_df, model, train_embeddings, train_df):\n",
    "    retriever = process_single_pdf(pdf_path)\n",
    "    llm_pipeline = setup_llm_pipeline()\n",
    "\n",
    "    answers = []\n",
    "    for _, row in questions_df.iterrows():\n",
    "        question = row['Question']\n",
    "        print(f\"Original question: {question}\")\n",
    "        \n",
    "        improved_question = improve_question(model, train_embeddings, train_df, question)\n",
    "        print(f\"Improved question: {improved_question}\")\n",
    "\n",
    "        result = llm_pipeline(improved_question)\n",
    "        \n",
    "        if isinstance(result, list):\n",
    "            answer_text = result[0]['generated_text'] if 'generated_text' in result[0] else result[0]\n",
    "        elif isinstance(result, dict):\n",
    "            answer_text = result.get('generated_text', result)\n",
    "        else:\n",
    "            answer_text = result\n",
    "\n",
    "        answers.append({\n",
    "            'SAMPLE_ID': row['SAMPLE_ID'], \n",
    "            'Answer': answer_text\n",
    "        })\n",
    "    \n",
    "    del retriever, llm_pipeline\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfbdf0c9-d1f6-404b-afb2-3eee45fbf849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_questions(df, model, train_embeddings, train_df):\n",
    "    all_answers = []\n",
    "    unique_paths = df['Source_path'].unique()\n",
    "\n",
    "    for path in tqdm(unique_paths, desc='Processing PDFs'):\n",
    "        pdf_questions_df = df[df['Source_path'] == path]\n",
    "        answers = process_questions_for_pdf(path, pdf_questions_df, model, train_embeddings, train_df)\n",
    "        all_answers.extend(answers)\n",
    "\n",
    "    return all_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4235ada-83cb-4080-ac45-6e32712c1d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Processing PDFs:   0%|                                                                           | 0/9 [00:00<?, ?it/s]c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started:  1724271947.7324545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaf995c19314aebaade58ba1035f0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 완전히 로드되지 않았습니다. 디스크 오프로드를 수행할 수 없습니다.\n",
      "Model loading time: 2.79 seconds\n",
      "Original question: 2022년 혁신창업사업화자금(융자)의 예산은 얼마인가요?\n",
      "Improved question: 창업사업화지원 사업의 2022년 결산 기준 예산 규모는 얼마인가?\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_df = load_train_data(args.train_csv_path)\n",
    "    question_improver_model, train_embeddings = train_question_improver(train_df)\n",
    "    \n",
    "    test_df = pd.read_csv(args.test_csv_path)\n",
    "    answers = process_test_questions(test_df, question_improver_model, train_embeddings, train_df)\n",
    "\n",
    "    output_path = os.path.join(args.output_dir, args.output_csv_file)\n",
    "    pd.DataFrame(answers).to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32104e-d00e-4fd0-b245-4704ecd0cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cb02bb7-dd61-4fd6-ba18-825df9763dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_results\\\\skt_kogpt2-base-v2_mobilebert-uncased_pdfpymupdf_chks256_chkovp16_bm250.5_faiss0.5_mix_submission.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafa113-df71-44c6-a9cb-20a0b4acee16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e27dbb8f-cfc3-4f56-b467-558df6193432",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = pd.read_csv(\"./test_results/skt_kogpt2-base-v2_mobilebert-uncased_pdfpymupdf_chks512_chkovp32_bm250.5_faiss0.5_mix_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed024df1-b85b-4868-91c5-acf35e62527f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>.\\n2018년부터 2020년 4월까지 사업비 확보율이 37.2%인데, 그중 가장 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>.\\n한편 ‘대한민국 신기술 창업의 주역으로서 중소기업 창업지원 및 산업기술 및 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>\", \"지원제도 도입 및 지원정책 현황 및 현황 실태\"등을 중심으로 설명하면서 \"관...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>??\\n창업기업이 사업화 성공률을 높일 수 있는 정책수단 중 하나로 창업기업에 대한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>?\\n(안건토론에서 가장 많이 답변한 건 창업한 기업과 창업한 기업의 매출액의 평균...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>TEST_093</td>\n",
       "      <td>\"라고 물었다.\\n이에 금융감독원 김용균 부원장은 \"금융소비자들의 체감수준 파악을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>TEST_094</td>\n",
       "      <td>\" 질문하였다.\\n질문이 끝나고 나서는 답변은 \"네\". \"어떻게 될 것인가\"였다.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TEST_095</td>\n",
       "      <td>\"\\n그는 이런 질문에 대해 \"회계원칙과 공공부문부채가 어떻게 다른가\"라는 답변인 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>TEST_096</td>\n",
       "      <td>\"라고 질문하면서 \"국민의 안전과 생명에 대한 투자를 증대하면 어떤 문제도 극복할 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TEST_097</td>\n",
       "      <td>\"라며 \"발행 주체도 이 전 대통령에게 있다\"라고 말했다.\\n이어 \"대통령의 발언과...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID                                             Answer\n",
       "0   TEST_000  .\\n2018년부터 2020년 4월까지 사업비 확보율이 37.2%인데, 그중 가장 ...\n",
       "1   TEST_001  .\\n한편 ‘대한민국 신기술 창업의 주역으로서 중소기업 창업지원 및 산업기술 및 기...\n",
       "2   TEST_002  \", \"지원제도 도입 및 지원정책 현황 및 현황 실태\"등을 중심으로 설명하면서 \"관...\n",
       "3   TEST_003  ??\\n창업기업이 사업화 성공률을 높일 수 있는 정책수단 중 하나로 창업기업에 대한...\n",
       "4   TEST_004  ?\\n(안건토론에서 가장 많이 답변한 건 창업한 기업과 창업한 기업의 매출액의 평균...\n",
       "..       ...                                                ...\n",
       "93  TEST_093  \"라고 물었다.\\n이에 금융감독원 김용균 부원장은 \"금융소비자들의 체감수준 파악을 ...\n",
       "94  TEST_094  \" 질문하였다.\\n질문이 끝나고 나서는 답변은 \"네\". \"어떻게 될 것인가\"였다.\\...\n",
       "95  TEST_095  \"\\n그는 이런 질문에 대해 \"회계원칙과 공공부문부채가 어떻게 다른가\"라는 답변인 ...\n",
       "96  TEST_096  \"라고 질문하면서 \"국민의 안전과 생명에 대한 투자를 증대하면 어떤 문제도 극복할 ...\n",
       "97  TEST_097  \"라며 \"발행 주체도 이 전 대통령에게 있다\"라고 말했다.\\n이어 \"대통령의 발언과...\n",
       "\n",
       "[98 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b90e2ee-5586-461b-b7cd-162a76c7a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f46cd205-dae9-4cc2-aa0a-e8dc726f01a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_path</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>중소벤처기업부_혁신창업사업화자금(융자)</td>\n",
       "      <td>./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf</td>\n",
       "      <td>2022년 혁신창업사업화자금(융자)의 예산은 얼마인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>중소벤처기업부_혁신창업사업화자금(융자)</td>\n",
       "      <td>./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf</td>\n",
       "      <td>중소벤처기업부의 혁신창업사업화자금(융자) 사업목적은 무엇인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>중소벤처기업부_혁신창업사업화자금(융자)</td>\n",
       "      <td>./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf</td>\n",
       "      <td>중소벤처기업부의 혁신창업사업화자금(융자) 사업근거는 어떤 법률에 근거하고 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>중소벤처기업부_혁신창업사업화자금(융자)</td>\n",
       "      <td>./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf</td>\n",
       "      <td>2010년에 신규 지원된 혁신창업사업화자금은 무엇인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>중소벤처기업부_혁신창업사업화자금(융자)</td>\n",
       "      <td>./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf</td>\n",
       "      <td>혁신창업사업화자금 중 2020년에 신규 지원된 자금은 무엇인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>TEST_093</td>\n",
       "      <td>「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》</td>\n",
       "      <td>./test_source/「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》...</td>\n",
       "      <td>재정정책에서 공적보증채무와 다른 일회성 보증은 어떻게 구분되는가?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>TEST_094</td>\n",
       "      <td>「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》</td>\n",
       "      <td>./test_source/「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》...</td>\n",
       "      <td>미래사회보장급여에 대한 순의무란 무엇을 의미하는가?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TEST_095</td>\n",
       "      <td>「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》</td>\n",
       "      <td>./test_source/「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》...</td>\n",
       "      <td>국가결산보고서와 지방자치단체 회계기준에서 우발부채에 대한 용어 및 회계처리가 어떻게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>TEST_096</td>\n",
       "      <td>「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》</td>\n",
       "      <td>./test_source/「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》...</td>\n",
       "      <td>우발부채란 무엇이며, 그 관리가 왜 중요한가?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TEST_097</td>\n",
       "      <td>「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》</td>\n",
       "      <td>./test_source/「FIS 이슈 &amp; 포커스」(신규) 통권 제1호 《우발부채》...</td>\n",
       "      <td>보증이란 무엇이며, 어떤 형태의 보증이 재정상태표에 부채로 기록되는가? 또한 표준화...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SAMPLE_ID                            Source  \\\n",
       "0   TEST_000             중소벤처기업부_혁신창업사업화자금(융자)   \n",
       "1   TEST_001             중소벤처기업부_혁신창업사업화자금(융자)   \n",
       "2   TEST_002             중소벤처기업부_혁신창업사업화자금(융자)   \n",
       "3   TEST_003             중소벤처기업부_혁신창업사업화자금(융자)   \n",
       "4   TEST_004             중소벤처기업부_혁신창업사업화자금(융자)   \n",
       "..       ...                               ...   \n",
       "93  TEST_093  「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》   \n",
       "94  TEST_094  「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》   \n",
       "95  TEST_095  「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》   \n",
       "96  TEST_096  「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》   \n",
       "97  TEST_097  「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》   \n",
       "\n",
       "                                          Source_path  \\\n",
       "0             ./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf   \n",
       "1             ./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf   \n",
       "2             ./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf   \n",
       "3             ./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf   \n",
       "4             ./test_source/중소벤처기업부_혁신창업사업화자금(융자).pdf   \n",
       "..                                                ...   \n",
       "93  ./test_source/「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》...   \n",
       "94  ./test_source/「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》...   \n",
       "95  ./test_source/「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》...   \n",
       "96  ./test_source/「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》...   \n",
       "97  ./test_source/「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》...   \n",
       "\n",
       "                                             Question  \n",
       "0                     2022년 혁신창업사업화자금(융자)의 예산은 얼마인가요?  \n",
       "1                 중소벤처기업부의 혁신창업사업화자금(융자) 사업목적은 무엇인가요?  \n",
       "2       중소벤처기업부의 혁신창업사업화자금(융자) 사업근거는 어떤 법률에 근거하고 있나요?  \n",
       "3                     2010년에 신규 지원된 혁신창업사업화자금은 무엇인가요?  \n",
       "4                혁신창업사업화자금 중 2020년에 신규 지원된 자금은 무엇인가요?  \n",
       "..                                                ...  \n",
       "93               재정정책에서 공적보증채무와 다른 일회성 보증은 어떻게 구분되는가?  \n",
       "94                       미래사회보장급여에 대한 순의무란 무엇을 의미하는가?  \n",
       "95  국가결산보고서와 지방자치단체 회계기준에서 우발부채에 대한 용어 및 회계처리가 어떻게...  \n",
       "96                          우발부채란 무엇이며, 그 관리가 왜 중요한가?  \n",
       "97  보증이란 무엇이며, 어떤 형태의 보증이 재정상태표에 부채로 기록되는가? 또한 표준화...  \n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9335a84c-5575-45fb-bc06-e1c26278fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4ba251e-071f-447e-b995-edb539817b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_path</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?</td>\n",
       "      <td>2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>기금이 예산과 다른 점은?</td>\n",
       "      <td>기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?</td>\n",
       "      <td>일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1-1 2024 주요 재정통계 1권</td>\n",
       "      <td>./train_source/1-1 2024 주요 재정통계 1권.pdf</td>\n",
       "      <td>2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?</td>\n",
       "      <td>2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>TRAIN_491</td>\n",
       "      <td>월간 나라재정 2023년 12월호</td>\n",
       "      <td>./train_source/월간 나라재정 2023년 12월호.pdf</td>\n",
       "      <td>자치단체 보조금과 민간보조금은 각각 어떤 비율로 증가했는가?</td>\n",
       "      <td>자치단체 보조금은 2019년 대비 2022년에 35% 증가하였고, 민간보조금은 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>TRAIN_492</td>\n",
       "      <td>월간 나라재정 2023년 12월호</td>\n",
       "      <td>./train_source/월간 나라재정 2023년 12월호.pdf</td>\n",
       "      <td>한국의 재정금융안정계획이 주로 어떤 목표에 초점을 맞추어 있었는가?</td>\n",
       "      <td>한국의 재정금융안정계획은 통화량 조절과 물가안정이라는 단기적 목표에 초점을 맞추어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>TRAIN_493</td>\n",
       "      <td>월간 나라재정 2023년 12월호</td>\n",
       "      <td>./train_source/월간 나라재정 2023년 12월호.pdf</td>\n",
       "      <td>1952년에 체결된 '한미경제조정협정'은 어떤 문제를 해결하기 위해 체결되었는가?</td>\n",
       "      <td>원조물자 판매대금의 효과적 활용, 참전유엔군 경비지출을 위해 우리 정부에서 대여해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>TRAIN_494</td>\n",
       "      <td>월간 나라재정 2023년 12월호</td>\n",
       "      <td>./train_source/월간 나라재정 2023년 12월호.pdf</td>\n",
       "      <td>2023년 12월 IMF는 성장 전망을 어떻게 제시하고 있으며, 성장세의 둔화가 어...</td>\n",
       "      <td>IMF는 최근 세계 경제전망을 통해 작년 3.5%에서 올해 3%, 내년 2.9%로 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>TRAIN_495</td>\n",
       "      <td>월간 나라재정 2023년 12월호</td>\n",
       "      <td>./train_source/월간 나라재정 2023년 12월호.pdf</td>\n",
       "      <td>한국의 재정금융안정계획이 주로 어떤 목표에 초점을 맞추어 있었는가?</td>\n",
       "      <td>한국의 재정금융안정계획은 통화량 조절과 물가안정이라는 단기적 목표에 초점을 맞추어 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAMPLE_ID               Source                             Source_path  \\\n",
       "0    TRAIN_000  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "1    TRAIN_001  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "2    TRAIN_002  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "3    TRAIN_003  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "4    TRAIN_004  1-1 2024 주요 재정통계 1권  ./train_source/1-1 2024 주요 재정통계 1권.pdf   \n",
       "..         ...                  ...                                     ...   \n",
       "491  TRAIN_491   월간 나라재정 2023년 12월호   ./train_source/월간 나라재정 2023년 12월호.pdf   \n",
       "492  TRAIN_492   월간 나라재정 2023년 12월호   ./train_source/월간 나라재정 2023년 12월호.pdf   \n",
       "493  TRAIN_493   월간 나라재정 2023년 12월호   ./train_source/월간 나라재정 2023년 12월호.pdf   \n",
       "494  TRAIN_494   월간 나라재정 2023년 12월호   ./train_source/월간 나라재정 2023년 12월호.pdf   \n",
       "495  TRAIN_495   월간 나라재정 2023년 12월호   ./train_source/월간 나라재정 2023년 12월호.pdf   \n",
       "\n",
       "                                              Question  \\\n",
       "0                       2024년 중앙정부 재정체계는 어떻게 구성되어 있나요?   \n",
       "1                     2024년 중앙정부의 예산 지출은 어떻게 구성되어 있나요?   \n",
       "2                                       기금이 예산과 다른 점은?   \n",
       "3                        일반회계, 특별회계, 기금 간의 차이점은 무엇인가요?   \n",
       "4             2024년 총수입은 얼마이며, 예산수입과 기금수입은 각각 몇 조원인가요?   \n",
       "..                                                 ...   \n",
       "491                  자치단체 보조금과 민간보조금은 각각 어떤 비율로 증가했는가?   \n",
       "492              한국의 재정금융안정계획이 주로 어떤 목표에 초점을 맞추어 있었는가?   \n",
       "493      1952년에 체결된 '한미경제조정협정'은 어떤 문제를 해결하기 위해 체결되었는가?   \n",
       "494  2023년 12월 IMF는 성장 전망을 어떻게 제시하고 있으며, 성장세의 둔화가 어...   \n",
       "495              한국의 재정금융안정계획이 주로 어떤 목표에 초점을 맞추어 있었는가?   \n",
       "\n",
       "                                                Answer  \n",
       "0    2024년 중앙정부 재정체계는 예산(일반·특별회계)과 기금으로 구분되며, 2024년...  \n",
       "1    2024년 중앙정부의 예산 지출은 일반회계 356.5조원, 21개 특별회계 81.7...  \n",
       "2    기금은 예산과 구분되는 재정수단으로서 재정운영의 신축성을 기할 필요가 있을 때, 정...  \n",
       "3    일반회계는 특정 사업 운영 및 특정 세입으로 특정 세출을 충당하는데 사용되고, 특별...  \n",
       "4    2024년 총수입은 612.2조원이며, 예산수입은 395.5조원, 기금수입은 216...  \n",
       "..                                                 ...  \n",
       "491  자치단체 보조금은 2019년 대비 2022년에 35% 증가하였고, 민간보조금은 10...  \n",
       "492  한국의 재정금융안정계획은 통화량 조절과 물가안정이라는 단기적 목표에 초점을 맞추어 ...  \n",
       "493  원조물자 판매대금의 효과적 활용, 참전유엔군 경비지출을 위해 우리 정부에서 대여해 ...  \n",
       "494  IMF는 최근 세계 경제전망을 통해 작년 3.5%에서 올해 3%, 내년 2.9%로 ...  \n",
       "495  한국의 재정금융안정계획은 통화량 조절과 물가안정이라는 단기적 목표에 초점을 맞추어 ...  \n",
       "\n",
       "[496 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
